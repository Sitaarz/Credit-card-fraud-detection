{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e52d68865f4f3cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "baca7be50fb46fe5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isnull().sum().max()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bf87ab1fcd00464"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8b6c3b2116ce8f3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('No frauds:',round(df['Class'].value_counts()[0]/len(df)*100,2), '% od the dataset')\n",
    "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2f1721b94a585fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "colors = [\"#0101DF\", \"#DF0101\"]\n",
    "\n",
    "sns.countplot(x= 'Class', data=df, palette=colors)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7aa05c26bec11cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(18,4))\n",
    "\n",
    "amount_val = df['Amount'].values\n",
    "time_val = df['Time'].values\n",
    "\n",
    "sns.distplot(amount_val, ax=ax[0], color='r')\n",
    "ax[0].set_title('Distribution of Transaction Amount', fontsize=14)\n",
    "ax[0].set_xlim([min(amount_val), max(amount_val)])\n",
    "\n",
    "sns.distplot(time_val, ax=ax[1], color='b')\n",
    "ax[1].set_title('Distribution of Transaction Time', fontsize=14)\n",
    "ax[1].set_xlim([min(time_val), max(time_val)])\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6092bb46c72c9421"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "556df0c4b90a8fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaled_amount = df['scaled_amount']\n",
    "scaled_time = df['scaled_time']\n",
    "\n",
    "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "# Amount and Time are Scaled!\n",
    "\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8111660bd293f1d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "    original_Xtrain, original_Xtest = X.iloc[train_index], X.iloc[test_index]\n",
    "    original_ytrain, original_ytest = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "# We already have X_train and y_train for undersample data thats why I am using original to distinguish and to not overwrite these variables.\n",
    "# original_Xtrain, original_Xtest, original_ytrain, original_ytest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the Distribution of the labels\n",
    "\n",
    "\n",
    "# Turn into an array\n",
    "original_Xtrain = original_Xtrain.values\n",
    "original_Xtest = original_Xtest.values\n",
    "original_ytrain = original_ytrain.values\n",
    "original_ytest = original_ytest.values\n",
    "\n",
    "# See if both the train and test label distribution are similarly distributed\n",
    "train_unique_label, train_counts_label = np.unique(original_ytrain, return_counts=True)\n",
    "test_unique_label, test_counts_label = np.unique(original_ytest, return_counts=True)\n",
    "print('-' * 100)\n",
    "\n",
    "print('Label Distributions: \\n')\n",
    "print(train_counts_label/ len(original_ytrain))\n",
    "print(test_counts_label/ len(original_ytest))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9222b5f3b0548dbd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Since our classes are highly skewed we should make them equivalent in order to have a normal distribution of the classes.\n",
    "\n",
    "# Lets shuffle the data before creating the subsamples\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "# amount of fraud classes 492 rows.\n",
    "fraud_df = df.loc[df['Class'] == 1]\n",
    "non_fraud_df = df.loc[df['Class'] == 0][:492]\n",
    "\n",
    "normal_distributed_df = pd.concat([fraud_df, non_fraud_df])\n",
    "\n",
    "# Shuffle dataframe rows\n",
    "new_df = normal_distributed_df.sample(frac=1, random_state=42)\n",
    "\n",
    "new_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3419700ea2e9f41"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Distribution of the Classes in the subsample dataset')\n",
    "print(new_df['Class'].value_counts()/len(new_df))\n",
    "\n",
    "\n",
    "\n",
    "sns.countplot(x='Class', data=new_df, palette=colors)\n",
    "plt.title('Equally Distributed Classes', fontsize=14)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15ec73574ff173e3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make sure we use the subsample in our correlation\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(24,20))\n",
    "\n",
    "# Entire DataFrame\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax1)\n",
    "ax1.set_title(\"Imbalanced Correlation Matrix \\n (don't use for reference)\", fontsize=14)\n",
    "\n",
    "\n",
    "sub_sample_corr = new_df.corr()\n",
    "sns.heatmap(sub_sample_corr, cmap='coolwarm_r', annot_kws={'size':20}, ax=ax2)\n",
    "ax2.set_title('SubSample Correlation Matrix \\n (use for reference)', fontsize=14)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ead2c5be73502250"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(ncols=4, figsize=(20,4))\n",
    "\n",
    "# Negative Correlations with our Class (The lower our feature value the more likely it will be a fraud transaction)\n",
    "sns.boxplot(x=\"Class\", y=\"V17\", data=new_df, palette=colors, ax=axes[0])\n",
    "axes[0].set_title('V17 vs Class Negative Correlation')\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V14\", data=new_df, palette=colors, ax=axes[1])\n",
    "axes[1].set_title('V14 vs Class Negative Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V12\", data=new_df, palette=colors, ax=axes[2])\n",
    "axes[2].set_title('V12 vs Class Negative Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V10\", data=new_df, palette=colors, ax=axes[3])\n",
    "axes[3].set_title('V10 vs Class Negative Correlation')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c30e5857d349e44"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(ncols=4, figsize=(20,4))\n",
    "\n",
    "# Negative Correlations with our Class (The lower our feature value the more likely it will be a fraud transaction)\n",
    "sns.boxplot(x=\"Class\", y=\"V17\", data=new_df, palette=colors, ax=axes[0])\n",
    "axes[0].set_title('V17 vs Class Negative Correlation')\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V14\", data=new_df, palette=colors, ax=axes[1])\n",
    "axes[1].set_title('V14 vs Class Negative Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V12\", data=new_df, palette=colors, ax=axes[2])\n",
    "axes[2].set_title('V12 vs Class Negative Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V10\", data=new_df, palette=colors, ax=axes[3])\n",
    "axes[3].set_title('V10 vs Class Negative Correlation')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6454e18f804c9e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(ncols=4, figsize=(20,4))\n",
    "\n",
    "# Positive correlations (The higher the feature the probability increases that it will be a fraud transaction)\n",
    "sns.boxplot(x=\"Class\", y=\"V11\", data=new_df, palette=colors, ax=axes[0])\n",
    "axes[0].set_title('V11 vs Class Positive Correlation')\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V4\", data=new_df, palette=colors, ax=axes[1])\n",
    "axes[1].set_title('V4 vs Class Positive Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V2\", data=new_df, palette=colors, ax=axes[2])\n",
    "axes[2].set_title('V2 vs Class Positive Correlation')\n",
    "\n",
    "\n",
    "sns.boxplot(x=\"Class\", y=\"V19\", data=new_df, palette=colors, ax=axes[3])\n",
    "axes[3].set_title('V19 vs Class Positive Correlation')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "811f5c91cc2e8cad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(20, 6))\n",
    "\n",
    "v14_fraud_dist = new_df['V14'].loc[new_df['Class'] == 1].values\n",
    "sns.distplot(v14_fraud_dist,ax=ax1, fit=norm, color='#FB8861')\n",
    "ax1.set_title('V14 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
    "\n",
    "v12_fraud_dist = new_df['V12'].loc[new_df['Class'] == 1].values\n",
    "sns.distplot(v12_fraud_dist,ax=ax2, fit=norm, color='#56F9BB')\n",
    "ax2.set_title('V12 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
    "\n",
    "\n",
    "v10_fraud_dist = new_df['V10'].loc[new_df['Class'] == 1].values\n",
    "sns.distplot(v10_fraud_dist,ax=ax3, fit=norm, color='#C5B3F9')\n",
    "ax3.set_title('V10 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "345845abfdb9d41f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # -----> V14 Removing Outliers (Highest Negative Correlated with Labels)\n",
    "v14_fraud = new_df['V14'].loc[new_df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v14_fraud, 25), np.percentile(v14_fraud, 75)\n",
    "print('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\n",
    "v14_iqr = q75 - q25\n",
    "print('iqr: {}'.format(v14_iqr))\n",
    "\n",
    "v14_cut_off = v14_iqr * 1.5\n",
    "v14_lower, v14_upper = q25 - v14_cut_off, q75 + v14_cut_off\n",
    "print('Cut Off: {}'.format(v14_cut_off))\n",
    "print('V14 Lower: {}'.format(v14_lower))\n",
    "print('V14 Upper: {}'.format(v14_upper))\n",
    "\n",
    "outliers = [x for x in v14_fraud if x < v14_lower or x > v14_upper]\n",
    "print('Feature V14 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
    "print('V10 outliers:{}'.format(outliers))\n",
    "\n",
    "new_df = new_df.drop(new_df[(new_df['V14'] > v14_upper) | (new_df['V14'] < v14_lower)].index)\n",
    "print('----' * 44)\n",
    "\n",
    "# -----> V12 removing outliers from fraud transactions\n",
    "v12_fraud = new_df['V12'].loc[new_df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v12_fraud, 25), np.percentile(v12_fraud, 75)\n",
    "print('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\n",
    "v12_iqr = q75 - q25\n",
    "\n",
    "v12_cut_off = v12_iqr * 1.5\n",
    "v12_lower, v12_upper = q25 - v12_cut_off, q75 + v12_cut_off\n",
    "print('V12 Lower: {}'.format(v12_lower))\n",
    "print('V12 Upper: {}'.format(v12_upper))\n",
    "outliers = [x for x in v12_fraud if x < v12_lower or x > v12_upper]\n",
    "print('V12 outliers: {}'.format(outliers))\n",
    "print('Feature V12 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
    "new_df = new_df.drop(new_df[(new_df['V12'] > v12_upper) | (new_df['V12'] < v12_lower)].index)\n",
    "print('Number of Instances after outliers removal: {}'.format(len(new_df)))\n",
    "print('----' * 44)\n",
    "\n",
    "\n",
    "# Removing outliers V10 Feature\n",
    "v10_fraud = new_df['V10'].loc[new_df['Class'] == 1].values\n",
    "q25, q75 = np.percentile(v10_fraud, 25), np.percentile(v10_fraud, 75)\n",
    "print('Quartile 25: {} | Quartile 75: {}'.format(q25, q75))\n",
    "v10_iqr = q75 - q25\n",
    "\n",
    "v10_cut_off = v10_iqr * 1.5\n",
    "v10_lower, v10_upper = q25 - v10_cut_off, q75 + v10_cut_off\n",
    "print('V10 Lower: {}'.format(v10_lower))\n",
    "print('V10 Upper: {}'.format(v10_upper))\n",
    "outliers = [x for x in v10_fraud if x < v10_lower or x > v10_upper]\n",
    "print('V10 outliers: {}'.format(outliers))\n",
    "print('Feature V10 Outliers for Fraud Cases: {}'.format(len(outliers)))\n",
    "new_df = new_df.drop(new_df[(new_df['V10'] > v10_upper) | (new_df['V10'] < v10_lower)].index)\n",
    "print('Number of Instances after outliers removal: {}'.format(len(new_df)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b89fb992ec689aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f,(ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,6))\n",
    "\n",
    "colors = ['#B3F9C5', '#f9c5b3']\n",
    "# Boxplots with outliers removed\n",
    "# Feature V14\n",
    "sns.boxplot(x=\"Class\", y=\"V14\", data=new_df,ax=ax1, palette=colors)\n",
    "ax1.set_title(\"V14 Feature \\n Reduction of outliers\", fontsize=14)\n",
    "\n",
    "\n",
    "# Feature 12\n",
    "sns.boxplot(x=\"Class\", y=\"V12\", data=new_df, ax=ax2, palette=colors)\n",
    "ax2.set_title(\"V12 Feature \\n Reduction of outliers\", fontsize=14)\n",
    "\n",
    "\n",
    "# Feature V10\n",
    "sns.boxplot(x=\"Class\", y=\"V10\", data=new_df, ax=ax3, palette=colors)\n",
    "ax3.set_title(\"V10 Feature \\n Reduction of outliers\", fontsize=14)\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33c113ddea514138"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X = new_df.drop('Class', axis=1)\n",
    "y = new_df['Class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_test = X_test.values\n",
    "y_train = y_train.values\n",
    "y_test = y_test.values\n",
    "\n",
    "logistic_regression_classifier = LogisticRegression()\n",
    "logistic_regression_classifier.fit(X_train,y_train)\n",
    "training_score = cross_val_score(logistic_regression_classifier, X_train, y_train, cv=5)\n",
    "\n",
    "print(round(training_score.mean(),2)*100, '% of accuracy.')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "669ba9619d3b181f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c856ca4607302484"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
